{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import chest_xray_code.data.xrays as preprocess_dataset\n",
    "import chest_xray_code.data.raw_reports as utils\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from models.TestConvNet import TestConvNet \n",
    "from loaders.BloodCellLoader import BloodCellLoader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n"
     ]
    }
   ],
   "source": [
    "trainset = BloodCellLoader(\n",
    "    root='blood_cells_data/dataset-master/JPEGImages',\n",
    "    preload=False, transform=transforms.ToTensor(),\n",
    ")\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "trainset_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=24)\n",
    "\n",
    "# load the testset\n",
    "# testset = Data_SET(\n",
    "#     root='chest_xray_code/data/xrays',\n",
    "#     preload=True, transform=transforms.ToTensor(),\n",
    "# )\n",
    "#testset = trainset\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "#testset_loader = DataLoader(testset, batch_size=1000, shuffle=False, num_workers=1)\n",
    "\n",
    "print(len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "                T.ToTensor()\n",
    "                #T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "images = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 \n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    #dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 3\n",
    "size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "images = []\n",
    "for data in trainset_loader:\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        img = data.cpu().detach()\n",
    "    \n",
    "        for i in range(img.shape[0]):\n",
    "            individual_img = img[i]\n",
    "            individual_img = individual_img.numpy()\n",
    "            individual_img = np.transpose(individual_img, (1, 2, 0))\n",
    "            images.append(torch.from_numpy(individual_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss(size_average=True)\n",
    "total_comparisons = 0\n",
    "comparison_sum = 0\n",
    "for i in range(len(images)):\n",
    "    for j in range(len(images)):\n",
    "        if i != j:\n",
    "            comparison_sum += loss_function(images[i],images[j])\n",
    "            total_comparisons += 1\n",
    "homogeneity = comparison_sum / total_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01453955564647913\n"
     ]
    }
   ],
   "source": [
    "print(homogeneity.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
