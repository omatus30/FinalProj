{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import chest_xray_code.data.xrays as preprocess_dataset\n",
    "import chest_xray_code.data.raw_reports as utils\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from models.NewConvModel import NewConvNet \n",
    "from models.TestConvNet import TestConvNet\n",
    "from loaders.XrayLoader import XrayLoader\n",
    "from loaders.BloodCellLoader import BloodCellLoader\n",
    "from loaders.MuseumLoader import MuseumLoader\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "366\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "xray_set = XrayLoader(\n",
    "    root='chest_xray_code/data/xrays',\n",
    "    preload=False, transform=transforms.ToTensor(),\n",
    ")\n",
    "xray_loader = DataLoader(xray_set, batch_size=20, shuffle=True, num_workers=32)\n",
    "\n",
    "blood_set = BloodCellLoader(\n",
    "    root='blood_cells_data/dataset-master/JPEGImages',\n",
    "    preload=False, transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "blood_cell_loader = DataLoader(blood_set, batch_size=20, shuffle=True, num_workers=32)\n",
    "\n",
    "\n",
    "museum_set = MuseumLoader(\n",
    "    root='museum_data/dataset_updated/training_set',\n",
    "    preload=False, transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "museum_loader = DataLoader(museum_set, batch_size=20, shuffle=True, num_workers=32)\n",
    "\n",
    "print(len(museum_set))\n",
    "print(len(blood_set))\n",
    "print(len(xray_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "                T.ToTensor()\n",
    "                #T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "images = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    #dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 3\n",
    "size = 32\n",
    "net_type = 'old'#'new' #'old'\n",
    "original_dataset = 'blood_cell' #'museum' #'xray' \n",
    "cross_dataset = 'blood_cell'\n",
    "model = None\n",
    "hook = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded blood_200_1000.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'models.TestConvNet.TestConvNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "if model == None: #ensure that we don't keep loading it over and over\n",
    "    if net_type == 'new':\n",
    "        model = NewConvNet(channels,size,device)\n",
    "        if original_dataset == 'blood_cell':\n",
    "            model = torch.load('trained_models/blood5.pt')\n",
    "            print(\"loaded blood5.pt\")\n",
    "        elif original_dataset == 'museum':\n",
    "            model = torch.load('trained_models/new_museum.pt')\n",
    "            print(\"loaded new_museum.pt\")\n",
    "        else:\n",
    "            model = torch.load('trained_models/new_xray.pt')\n",
    "            print(\"loaded new_xray.pt\")\n",
    "    else:\n",
    "        model = TestConvNet(channels,size)\n",
    "        if original_dataset == 'blood_cell':\n",
    "            model = torch.load('trained_models/blood_200_1000.pt')\n",
    "            print(\"loaded blood_200_1000.pt\")\n",
    "        elif original_dataset == 'museum':\n",
    "            model = torch.load('trained_models/old_museum.pt')\n",
    "            print(\"loaded old_museum.pt\")\n",
    "        else:\n",
    "            model = torch.load('trained_models/xraymodelV2.pt')\n",
    "            print(\"loaded xraymodelV2.pt\")\n",
    "\n",
    "        model.to(device)\n",
    "        \n",
    "        \n",
    "if cross_dataset == 'museum':\n",
    "    cross_dataset_loader = museum_loader\n",
    "elif cross_dataset == 'xray':\n",
    "    cross_dataset_loader = xray_loader\n",
    "else:\n",
    "    cross_dataset_loader = blood_cell_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the Compressed images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(img):\n",
    "    img = img.numpy()\n",
    "    if True:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = .9* (img - img_min) / (img_max - img_min) \n",
    "    return np.transpose(img, (1, 2, 0)) \n",
    "\n",
    "def save_compressed(self,input,output):\n",
    "    #for i in range(1):\n",
    "    img = output.cpu().detach()\n",
    "    for i in range(img.shape[0]):\n",
    "        individual_img = img[i]\n",
    "        images[1].append(prep(individual_img))\n",
    "\n",
    "        \n",
    "def save_original(data):\n",
    "    img = data.cpu().detach()\n",
    "\n",
    "    for i in range(img.shape[0]):\n",
    "        individual_img = img[i]\n",
    "        individual_img = individual_img.numpy()\n",
    "        individual_img = np.transpose(individual_img, (1, 2, 0))\n",
    "        images[0].append(individual_img)\n",
    "\n",
    "def visualize(net_type,original_dataset,cross_dataset,device):\n",
    "    model = None\n",
    "    \n",
    "\n",
    "    if model == None: #ensure that we don't keep loading it over and over\n",
    "        if net_type == 'new':\n",
    "            model = NewConvNet(channels,size,device)\n",
    "            if original_dataset == 'blood_cell':\n",
    "                model = torch.load('trained_models/blood5.pt')\n",
    "                print(\"loaded blood5.pt\")\n",
    "            elif original_dataset == 'museum':\n",
    "                model = torch.load('trained_models/new_museum.pt')\n",
    "                print(\"loaded new_museum.pt\")\n",
    "            else:\n",
    "                model = torch.load('trained_models/new_xray.pt')\n",
    "                print(\"loaded new_xray.pt\")\n",
    "        else:\n",
    "            model = TestConvNet(channels,size)\n",
    "            if original_dataset == 'blood_cell':\n",
    "                model = torch.load('trained_models/blood_200_1000.pt')\n",
    "                print(\"loaded blood_200_1000.pt\")\n",
    "            elif original_dataset == 'museum':\n",
    "                model = torch.load('trained_models/old_museum.pt')\n",
    "                print(\"loaded old_museum.pt\")\n",
    "            else:\n",
    "                model = torch.load('trained_models/xraymodelV2.pt')\n",
    "                print(\"loaded xraymodelV2.pt\")\n",
    "\n",
    "            model.to(device)\n",
    "            \n",
    "    if hook == None: \n",
    "        hook = model.conv_compress_final.register_forward_hook(save_compressed)     \n",
    "        \n",
    "        \n",
    "    if cross_dataset == 'museum':\n",
    "        cross_dataset_loader = museum_loader\n",
    "    elif cross_dataset == 'xray':\n",
    "        cross_dataset_loader = xray_loader\n",
    "    else:\n",
    "        cross_dataset_loader = blood_cell_loader\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.close(\"all\")\n",
    "\n",
    "\n",
    "    images = [[],[]]\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    reconstruction = None\n",
    "    for data in cross_dataset_loader:\n",
    "        with torch.no_grad():\n",
    "            if i > 0: break\n",
    "            data = data.to(device)\n",
    "            save_original(data)\n",
    "            reconstruction = model(data)\n",
    "            i+=1\n",
    "\n",
    "    for i in range(10):\n",
    "        plt.figure(figsize=(100,100))\n",
    "        #plt.figure()\n",
    "        org = images[0][i]\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.axis('off')\n",
    "        #imshow_noax(org, normalize=False)\n",
    "        plt.imshow(org)\n",
    "        plt.title('Original')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        rec = images[1][i]\n",
    "        plt.imshow(rec)\n",
    "        #imshow_noax(rec, normalize=False)\n",
    "        plt.title('Compressed')\n",
    "        plt.axis('off')\n",
    "        image_str = net_type + \"_\" + original_dataset + \"_\" +cross_dataset+\"_\"+str(i) + \".png\"\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.axis('off')\n",
    "        recon = reconstruction[i].cpu().detach()\n",
    "        recon = recon.numpy()\n",
    "        recon = np.transpose(recon,(1,2,0))\n",
    "        recon = np.clip(recon,0,1)\n",
    "        plt.imshow(recon)\n",
    "        plt.title('Reconstructed')\n",
    "        plt.savefig(\"cross_visualizations/\"+image_str)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store Images as JPEG with same compression rate that we are achieving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpg_images = [[],[],[]]\n",
    "\n",
    "def check_sizes(img):\n",
    "    for i in range(1,100):\n",
    "        jpeg_filename = \"jpeg_visualizations/\" + str(i) + \"_jaypeg.jpeg\"\n",
    "        img.save(jpeg_filename,\"JPEG\",quality=i)\n",
    "        jpeg_compressed = Image.open(jpeg_filename)\n",
    "        jpeg_compressed = np.asarray(jpeg_compressed)\n",
    "        print(jpeg_compressed.shape,i)\n",
    "        \n",
    "        \n",
    "\n",
    "def save_original_and_jpeg(data):\n",
    "    img = data.cpu().detach()\n",
    "\n",
    "    for i in range(img.shape[0]):\n",
    "        individual_img = img[i]\n",
    "        individual_img = individual_img.numpy()\n",
    "        individual_img = np.transpose(individual_img, (1, 2, 0))\n",
    "        jpg_images[0].append(individual_img)\n",
    "\n",
    "        rescaled = (255.0 * individual_img)\n",
    "        rescaled = rescaled.astype('uint8')\n",
    "        \n",
    "        PIL_img = Image.fromarray(rescaled)\n",
    "        #check_sizes(PIL_img)\n",
    "        jpeg_filename = \"jpeg_visualizations/\" + str(i) + \"_jaypeg.jpeg\"\n",
    "        PIL_img.save(jpeg_filename,\"JPEG\",quality=100)\n",
    "     \n",
    "        jpeg_compressed = Image.open(jpeg_filename)\n",
    "        jpeg_compressed = np.asarray(jpeg_compressed)\n",
    "        jpg_images[2].append(jpeg_compressed)\n",
    "        \n",
    "def save_reconstruction(reconstruction):\n",
    "    for i in range(reconstruction.shape[0]):\n",
    "        recon = reconstruction[i].cpu().detach()\n",
    "        recon = recon.numpy()\n",
    "        recon = np.transpose(recon,(1,2,0))\n",
    "        recon = np.clip(recon,0,1)\n",
    "        jpg_images[1].append(recon)\n",
    "        \n",
    "i = 0\n",
    "for data in cross_dataset_loader:\n",
    "        with torch.no_grad():\n",
    "            if i > 0: break\n",
    "            data = data.to(device)\n",
    "            save_original_and_jpeg(data)\n",
    "            reconstruction = model(data)\n",
    "            save_reconstruction(reconstruction)\n",
    "            i+=1\n",
    "            \n",
    "for i in range(10):\n",
    "        plt.figure(figsize=(100,100))\n",
    "        #plt.figure()\n",
    "        org = jpg_images[0][i]\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.axis('off')\n",
    "        #imshow_noax(org, normalize=False)\n",
    "        plt.imshow(org)\n",
    "        plt.title('Original')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        rec = jpg_images[1][i]\n",
    "        plt.imshow(rec)\n",
    "        #imshow_noax(rec, normalize=False)\n",
    "        plt.title('Reconstructed')\n",
    "        plt.axis('off')\n",
    "        image_str = net_type + \"_\" + original_dataset + \"_\" +cross_dataset+\"_\"+str(i) + \".png\"\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(jpg_images[2][i])\n",
    "        plt.title('jpeg')\n",
    "        #plt.savefig(\"cross_visualizations/\"+image_str)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not working until all models are trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_datasets = ['xray','museum','blood_cell']#'museum' #'xray' #'blood_cell'\n",
    "net_types = ['new','old'] #'old'\n",
    "original_datasets = ['xray','museum','blood_cell'] #'museum' #'xray' \n",
    "\n",
    "for net_type in net_types:\n",
    "    for original_dataset in original_datasets:\n",
    "        for cross_dataset in cross_datasets:\n",
    "            visualize(net_type,original_dataset,cross_dataset,device)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the Reconstructed Images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
