{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import chest_xray_code.data.xrays as preprocess_dataset\n",
    "import chest_xray_code.data.raw_reports as utils\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(osp.join('museum_data/dataset_updated/training_set', '*.jpg'))\n",
    "#print(filenames)\n",
    "\n",
    "for filename in filenames:\n",
    "    image_fn = filename\n",
    "    try:\n",
    "        #print(image_fn)\n",
    "        image = Image.open(image_fn)\n",
    "        image = image.resize((200,200),Image.ANTIALIAS)\n",
    "    except IOError:\n",
    "        os.remove(image_fn)\n",
    "        print(image_fn)    \n",
    "\n",
    "    removed_name = False\n",
    "    if image is None:\n",
    "        os.remove(image_fn)\n",
    "        print(image_fn)\n",
    "        removed_name = True\n",
    "    image = np.array(image)\n",
    "\n",
    "    if image.shape != (200,200,3):\n",
    "        os.remove(image_fn)\n",
    "        print(image_fn)\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#X, Y = utils.load_X_and_Y()\n",
    "#x_train, x_dev, x_test = X\n",
    "#y_train, y_dev, y_test = Y\n",
    "\n",
    "class Data_SET(Dataset):\n",
    "    \"\"\"\n",
    "    A customized data loader for MNIST.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 transform=None,\n",
    "                 preload=False):\n",
    "        \"\"\" Intialize the MNIST dataset\n",
    "        \n",
    "        Args:\n",
    "            - root: root directory of the dataset\n",
    "            - tranform: a custom tranform function\n",
    "            - preload: if preload the dataset into memory\n",
    "        \"\"\"\n",
    "        self.images = None\n",
    "        self.labels = None\n",
    "        self.filenames = []\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        # read filenames\n",
    "        filenames = glob.glob(osp.join(root, '*.jpg'))\n",
    "        \n",
    "        \n",
    "        #randomly select filenames for more even distribution\n",
    "        sample_size = 500\n",
    "        #import pdb; pdb.set_trace();\n",
    "        file_samples =  random.sample(filenames, sample_size)\n",
    "        \n",
    "        for fn in file_samples:\n",
    "            self.filenames.append(fn) # (filename, label) pair\n",
    "\n",
    " \n",
    "\n",
    "        # if preload dataset into memory\n",
    "        if preload:\n",
    "            self._preload()\n",
    "            \n",
    "        self.len = len(self.filenames)\n",
    "                              \n",
    "    def _preload(self):\n",
    "        \"\"\"\n",
    "        Preload dataset to memory\n",
    "        \"\"\"\n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "        for image_fn in self.filenames:            \n",
    "            # load images\n",
    "            image = Image.open(image_fn)\n",
    "            # avoid too many opened files bug\n",
    "            self.images.append(image.copy())\n",
    "            image.close()\n",
    "            #self.labels.append(label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get a sample from the dataset\n",
    "        \"\"\"\n",
    "                \n",
    "        if self.images is not None:\n",
    "            # If dataset is preloaded\n",
    "            image = self.images[index]\n",
    "        else:\n",
    "            # If on-demand data loading\n",
    "            try:\n",
    "                image_fn = self.filenames[index]\n",
    "                image = Image.open(image_fn)\n",
    "                image = image.resize((200,200),Image.ANTIALIAS)\n",
    "            except IOError:\n",
    "                os.remove(image_fn)\n",
    "                print(image_fn)\n",
    "            #image = image[:,0:200,0:200]\n",
    "            \n",
    "        # May use transform function to transform samples\n",
    "        # e.g., random crop, whitening\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        # return image and label\n",
    "\n",
    "                \n",
    "        return image[:,:200,:200]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len\n",
    "    \n",
    "trainset = Data_SET(\n",
    "    root='museum_data/dataset_updated/training_set',\n",
    "    preload=False, transform=transforms.ToTensor(),\n",
    ")\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "trainset_loader = DataLoader(trainset, batch_size=20, shuffle=True, num_workers=32)\n",
    "\n",
    "# load the testset\n",
    "# testset = Data_SET(\n",
    "#     root='chest_xray_code/data/xrays',\n",
    "#     preload=True, transform=transforms.ToTensor(),\n",
    "# )\n",
    "#testset = trainset\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "#testset_loader = DataLoader(testset, batch_size=1000, shuffle=False, num_workers=1)\n",
    "\n",
    "print(len(trainset))\n",
    "#print(len(testset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_noax(img, normalize=True):\n",
    "    \"\"\" Tiny helper to show images as uint8 and remove axis labels \"\"\"\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "    plt.imshow(img)\n",
    "    plt.gca().axis('off')\n",
    "    \n",
    "    # functions to show an image\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "#dataiter = iter(trainset_loader)\n",
    "\n",
    "#images = dataiter.next()\n",
    "\n",
    "# show images\n",
    "#imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 100\n",
    "\n",
    "transform = T.Compose([\n",
    "                T.ToTensor()\n",
    "                #T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "loader_train = trainset\n",
    "images = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    #dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "def test_flatten():\n",
    "    x = torch.arange(12).view(2, 1, 3, 2)\n",
    "    print('Before flattening: ', x)\n",
    "    print('After flattening: ', flatten(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):  \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            #y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "\n",
    "        \n",
    "    i = 0\n",
    "    for image in x:\n",
    "        images[image] = scores[i]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class TestConvNet(nn.Module):\n",
    "    def __init__(self,channels,size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_1_compress = nn.Conv2d(channels, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.relu_1_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_2_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_2_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_2_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_3_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_3_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_3_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_4_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_4_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_4_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_5_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_5_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_5_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_6_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_6_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_6_compress = nn.ReLU()\n",
    "\n",
    "        self.conv_downsize_compress = nn.Conv2d(size, size, kernel_size=3,stride=2,padding=1,bias=True)\n",
    "        self.batchnorm_downsize_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_downsize_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_7_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_7_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_7_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_8_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_8_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_8_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_9_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_9_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_9_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_10_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_10_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_10_compress = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_compress_final = nn.Conv2d(size, channels, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        \n",
    "        self.upscaling = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.conv_1_decompress = nn.Conv2d(channels, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.relu_1_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_2_decompress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_2_decompress = nn.BatchNorm2d(size)\n",
    "        self.relu_2_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_3_decompress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_3_decompress = nn.BatchNorm2d(size)\n",
    "        self.relu_3_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_4_decompress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_4_decompress = nn.BatchNorm2d(size)\n",
    "        self.relu_4_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_5_decompress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_5_decompress = nn.BatchNorm2d(size)\n",
    "        self.relu_5_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_6_decompress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_6_decompress = nn.BatchNorm2d(size)\n",
    "        self.relu_6_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_7_decompress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_7_decompress = nn.BatchNorm2d(size)\n",
    "        self.relu_7_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_8_decompress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_8_decompress = nn.BatchNorm2d(size)\n",
    "        self.relu_8_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_9_decompress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_9_decompress = nn.BatchNorm2d(size)\n",
    "        self.relu_9_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_10_decompress = nn.Conv2d(size, 3, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = None\n",
    "        model = torch.nn.Sequential( \n",
    "            \n",
    "            self.conv_1_compress,\n",
    "            self.relu_1_compress,\n",
    "        \n",
    "            self.conv_2_compress,\n",
    "            self.batchnorm_2_compress,\n",
    "            self.relu_2_compress,\n",
    "            \n",
    "            self.conv_3_compress,\n",
    "            self.batchnorm_3_compress,\n",
    "            self.relu_3_compress,\n",
    "            \n",
    "            self.conv_4_compress,\n",
    "            self.batchnorm_4_compress,\n",
    "            self.relu_4_compress,\n",
    "            \n",
    "            self.conv_5_compress,\n",
    "            self.batchnorm_5_compress,\n",
    "            self.relu_5_compress,\n",
    "            \n",
    "            self.conv_6_compress,\n",
    "            self.batchnorm_6_compress,\n",
    "            self.relu_6_compress,\n",
    "            \n",
    "            self.conv_downsize_compress,\n",
    "            self.batchnorm_downsize_compress,\n",
    "            self.relu_downsize_compress,\n",
    "            \n",
    "            self.conv_7_compress,\n",
    "            self.batchnorm_7_compress,\n",
    "            self.relu_7_compress,\n",
    "            \n",
    "            self.conv_8_compress,\n",
    "            self.batchnorm_8_compress,\n",
    "            self.relu_8_compress,\n",
    "            \n",
    "            self.conv_9_compress,\n",
    "            self.batchnorm_9_compress,\n",
    "            self.relu_9_compress,\n",
    "            \n",
    "            self.conv_10_compress,\n",
    "            self.batchnorm_10_compress,\n",
    "            self.relu_10_compress,\n",
    "            \n",
    "            self.conv_compress_final,\n",
    "        \n",
    "            self.upscaling,\n",
    "            \n",
    "            self.conv_1_decompress,\n",
    "            self.relu_1_decompress,\n",
    "        \n",
    "            self.conv_2_decompress,\n",
    "            self.batchnorm_2_decompress,\n",
    "            self.relu_2_decompress,\n",
    "            \n",
    "            self.conv_3_decompress,\n",
    "            self.batchnorm_3_decompress,\n",
    "            self.relu_3_decompress,\n",
    "            \n",
    "            self.conv_4_decompress,\n",
    "            self.batchnorm_4_decompress,\n",
    "            self.relu_4_decompress,\n",
    "            \n",
    "            self.conv_5_decompress,\n",
    "            self.batchnorm_5_decompress,\n",
    "            self.relu_5_decompress,\n",
    "            \n",
    "            self.conv_6_decompress,\n",
    "            self.batchnorm_6_decompress,\n",
    "            self.relu_6_decompress,\n",
    "            \n",
    "            self.conv_7_decompress,\n",
    "            self.batchnorm_7_decompress,\n",
    "            self.relu_7_decompress,\n",
    "            \n",
    "            self.conv_8_decompress,\n",
    "            self.batchnorm_8_decompress,\n",
    "            self.relu_8_decompress,\n",
    "            \n",
    "            self.conv_9_decompress,\n",
    "            self.batchnorm_9_decompress,\n",
    "            self.relu_9_decompress,\n",
    "        \n",
    "            self.conv_10_decompress\n",
    "\n",
    "            \n",
    "        ).to(device)\n",
    "        scores = model(x)\n",
    "        return scores\n",
    "    \n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval=100):\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.train()  # set training mode\n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        for batch_idx, (data) in enumerate(trainset_loader):\n",
    "            data = data.to(device=device, dtype=dtype)\n",
    "            optimizer.zero_grad()\n",
    "            #print(data.shape)\n",
    "            reconstruction = model(data)\n",
    "            loss_function = nn.MSELoss(size_average=True)\n",
    "            loss = loss_function(reconstruction, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if ep % print_every == 0:\n",
    "            print('Iteration %d, loss = %.4f' % (ep, loss.item()))\n",
    "            print()\n",
    "\n",
    "def test():\n",
    "    model.eval()  # set evaluation mode\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testset_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(testset_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(testset_loader.dataset),\n",
    "        100. * correct / len(testset_loader.dataset)))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "channels = 3\n",
    "size = 32\n",
    "\n",
    "#model = TestConvNet(channels, size)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=5e-3)    \n",
    "    \n",
    "\n",
    "#train(model,1500)\n",
    "\n",
    "#torch.save(model, 'MuseumModel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class save_output(nn.Module):\n",
    "    def forward(self, x):\n",
    "       \n",
    "        with torch.no_grad():\n",
    "            img = x.cpu().detach()\n",
    "            imshow_noax(torchvision.utils.make_grid(img))\n",
    "        return x\n",
    "\"\"\"\n",
    "plt.close(\"all\")\n",
    "f,axarr = plt.subplots(20, 2,figsize=(400,400))\n",
    "\n",
    "f.tight_layout()\n",
    "f.subplots_adjust(left=0, bottom=0, right=.1, top=.1, wspace=0, hspace=.1)\n",
    "\n",
    "images = [[],[]]\n",
    "\n",
    "def prep(img):\n",
    "    img = img.numpy()\n",
    "    if True:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "    return np.transpose(img, (1, 2, 0))\n",
    "    \n",
    "def save_compressed(self,input,output):\n",
    "    #for i in range(1):\n",
    "    img = output.cpu().detach()\n",
    "    for i in range(img.shape[0]):\n",
    "\n",
    "        individual_img = img[i]\n",
    "        axarr[i,1].axis('off')\n",
    "        axarr[i,1].imshow(prep(individual_img))\n",
    "        images[1].append(prep(individual_img))\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "def save_original(data):\n",
    "    img = data.cpu().detach()\n",
    "    \n",
    "    for i in range(img.shape[0]):\n",
    "        individual_img = img[i]\n",
    "        individual_img = individual_img.numpy()\n",
    "        individual_img = np.transpose(individual_img, (1, 2, 0))\n",
    "        axarr[i,0].axis('off')\n",
    "        axarr[i,0].imshow(individual_img)\n",
    "        images[0].append(individual_img)\n",
    "\n",
    "\n",
    "\n",
    "model = torch.load('MuseumModel.pt')\n",
    "\n",
    "model.conv_compress_final.register_forward_hook(save_compressed)\n",
    "i = 0\n",
    "reconstruction = None\n",
    "for data in trainset_loader:\n",
    "    with torch.no_grad():\n",
    "        if i > 0: break\n",
    "        data = data.to(device)\n",
    "        display_original(data)\n",
    "        reconstruction = model(data)\n",
    "        i+=1\n",
    "\"\"\"\n",
    "for i in range(20):\n",
    "    plt.figure()\n",
    "    org = images[0][i]\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.axis('off')\n",
    "    #imshow_noax(org, normalize=False)\n",
    "    plt.imshow(org)\n",
    "    plt.title('Original image')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    rec = images[1][i]\n",
    "    plt.imshow(rec)\n",
    "    #imshow_noax(rec, normalize=False)\n",
    "    plt.title('Compressed Image')\n",
    "    plt.axis('off')\n",
    "    image_str = str(i) + \".png\"\n",
    "    plt.savefig(image_str)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(20):\n",
    "#    plt.figure()\n",
    "#    org = originals[i].cpu().detach().numpy().transpose(1,2,0)\n",
    "    #org = np.maximum(org,1)\n",
    "    #org = np.minimum(org,0)\n",
    "#    plt.subplot(1, 2, 1)\n",
    "#    imshow_noax(org, normalize=False)\n",
    "#    plt.title('Original image')\n",
    "#    plt.subplot(1, 2, 2)\n",
    "#    rec = reconstruction[i].cpu().detach().numpy().transpose(1,2,0)\n",
    "    #rec = np.maximum(rec,1)\n",
    "    #rec = np.minimum(rec,0)\n",
    "#    imshow_noax(rec, normalize=False)\n",
    "#    plt.title('Reconstructed image')\n",
    "#    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
