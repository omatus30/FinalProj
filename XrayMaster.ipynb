{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to <code>/chest_xray_code/data</code> and run \n",
    "<code>wget https://openi.nlm.nih.gov/imgs/collections/NLMCXR_png.tgz</code>\n",
    "<code>wget https://openi.nlm.nih.gov/imgs/collections/NLMCXR_reports.tgz</code>\n",
    "\n",
    "Then decompress them, and make sure they're in a directory called <code>/raw_reports</code> and <code>/xrays</code> respectively... (one of them decompresses to its own directory, so you need to rename that directory raw_reports instead of encgn or whatever).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import chest_xray_code.data.xrays as preprocess_dataset\n",
    "import chest_xray_code.data.raw_reports as utils\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to final_proj_code/chest_xray_code/src and run \n",
    "\n",
    "<code> python preprocess_dataset.py </code>\n",
    "\n",
    "Now the data is stored in a numpy array in <code>../data/dataset.npy</code> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "#X, Y = utils.load_X_and_Y()\n",
    "#x_train, x_dev, x_test = X\n",
    "#y_train, y_dev, y_test = Y\n",
    "\n",
    "class Data_SET(Dataset):\n",
    "    \"\"\"\n",
    "    A customized data loader for MNIST.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 transform=None,\n",
    "                 preload=False):\n",
    "        \"\"\" Intialize the MNIST dataset\n",
    "        \n",
    "        Args:\n",
    "            - root: root directory of the dataset\n",
    "            - tranform: a custom tranform function\n",
    "            - preload: if preload the dataset into memory\n",
    "        \"\"\"\n",
    "        self.images = None\n",
    "        self.labels = None\n",
    "        self.filenames = []\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        # read filenames\n",
    "        filenames = glob.glob(osp.join(root, '*.png'))\n",
    "        i = 0\n",
    "        for fn in filenames:\n",
    "            #print('in loop',fn)\n",
    "            self.filenames.append(fn) # (filename, label) pair\n",
    "            i +=1\n",
    "            if i == 300:\n",
    "                break\n",
    "\n",
    "        # if preload dataset into memory\n",
    "        if preload:\n",
    "            self._preload()\n",
    "            \n",
    "        self.len = len(self.filenames)\n",
    "                              \n",
    "    def _preload(self):\n",
    "        \"\"\"\n",
    "        Preload dataset to memory\n",
    "        \"\"\"\n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "        for image_fn in self.filenames:            \n",
    "            # load images\n",
    "            image = Image.open(image_fn)\n",
    "            # avoid too many opened files bug\n",
    "            self.images.append(image.copy())\n",
    "            image.close()\n",
    "            #self.labels.append(label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get a sample from the dataset\n",
    "        \"\"\"\n",
    "        if self.images is not None:\n",
    "            # If dataset is preloaded\n",
    "            image = self.images[index]\n",
    "            #label = self.labels[index]\n",
    "        else:\n",
    "            # If on-demand data loading\n",
    "            image_fn = self.filenames[index]\n",
    "            image = Image.open(image_fn)\n",
    "            \n",
    "        # May use transform function to transform samples\n",
    "        # e.g., random crop, whitening\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        # return image and label\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len\n",
    "    \n",
    "trainset = Data_SET(\n",
    "    root='chest_xray_code/data/xrays',\n",
    "    preload=False, transform=transforms.ToTensor(),\n",
    ")\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "trainset_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=1)\n",
    "\n",
    "# load the testset\n",
    "# testset = Data_SET(\n",
    "#     root='chest_xray_code/data/xrays',\n",
    "#     preload=True, transform=transforms.ToTensor(),\n",
    "# )\n",
    "#testset = trainset\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "#testset_loader = DataLoader(testset, batch_size=1000, shuffle=False, num_workers=1)\n",
    "\n",
    "print(len(trainset))\n",
    "#print(len(testset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_noax(img, normalize=True):\n",
    "    \"\"\" Tiny helper to show images as uint8 and remove axis labels \"\"\"\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "    plt.imshow(img)\n",
    "    plt.gca().axis('off')\n",
    "    \n",
    "    # functions to show an image\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "# dataiter = iter(trainset_loader)\n",
    "# images = dataiter.next()\n",
    "\n",
    "#images = trainset.__getitem__(5)\n",
    "\n",
    "# show images\n",
    "#imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "#print(' '.join('%5s' % labels[j] for j in range(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 100\n",
    "\n",
    "# The torchvision.transforms package provides tools for preprocessing data\n",
    "# and for performing data augmentation; here we set up a transform to\n",
    "# preprocess the data by subtracting the mean RGB value and dividing by the\n",
    "# standard deviation of each RGB value; we've hardcoded the mean and std.\n",
    "transform = T.Compose([\n",
    "                T.ToTensor()\n",
    "                #T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
    "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
    "# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
    "# training set into train and val sets by passing a Sampler object to the\n",
    "# DataLoader telling how it should sample from the underlying Dataset.\n",
    "#cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "#                             transform=transform)\n",
    "# loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "#                           sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "loader_train = trainset\n",
    "\n",
    "#cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "#                           transform=transform)\n",
    "#loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "#                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 150)))\n",
    "\n",
    "#cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n",
    "#                            transform=transform)\n",
    "#loader_test = DataLoader(cifar10_test, batch_size=64)\n",
    "#loader_test = testset\n",
    "\n",
    "images = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have an option to **use GPU by setting the flag to True below**. It is not necessary to use GPU for this assignment. Note that if your computer does not have CUDA enabled, `torch.cuda.is_available()` will return False and this notebook will fallback to CPU mode.\n",
    "\n",
    "The global variables `dtype` and `device` will control the data types throughout this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    #dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 5\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "def test_flatten():\n",
    "    x = torch.arange(12).view(2, 1, 3, 2)\n",
    "    print('Before flattening: ', x)\n",
    "    print('After flattening: ', flatten(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module API: Check Accuracy\n",
    "Given the validation or test set, we can check the classification accuracy of a neural network. \n",
    "\n",
    "This version is slightly different from the one in part II. You don't manually pass in the parameters anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):  \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            #y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "\n",
    "        \n",
    "    i = 0\n",
    "    for image in x:\n",
    "        images[image] = scores[i]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module API: Training Loop\n",
    "We also use a slightly different training loop. Rather than updating the values of the weights ourselves, we use an Optimizer object from the `torch.optim` package, which abstract the notion of an optimization algorithm and provides implementations of most of the algorithms commonly used to optimize neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV. PyTorch Sequential API\n",
    "\n",
    "Part III introduced the PyTorch Module API, which allows you to define arbitrary learnable layers and their connectivity. \n",
    "\n",
    "For simple models like a stack of feed forward layers, you still need to go through 3 steps: subclass `nn.Module`, assign layers to class attributes in `__init__`, and call each layer one by one in `forward()`. Is there a more convenient way? \n",
    "\n",
    "Fortunately, PyTorch provides a container Module called `nn.Sequential`, which merges the above steps into one. It is not as flexible as `nn.Module`, because you cannot specify more complex topology than a feed-forward stack, but it's good enough for many use cases.\n",
    "\n",
    "### Sequential API: Two-Layer Network\n",
    "Let's see how to rewrite our two-layer fully connected network example with `nn.Sequential`, and train it using the training loop defined above.\n",
    "\n",
    "Again, you don't need to tune any hyperparameters here, but you shoud achieve above 40% accuracy after one epoch of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=5):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    loss_history = []\n",
    "    j = 0\n",
    "    for e in range(epochs):\n",
    "        i = 0\n",
    "        for im in range(0,12):\n",
    "            x = trainset.__getitem__(i)\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            #y = y.to(device=device, dtype=torch.float)\n",
    "            #print(x.shape)\n",
    "            z = torch.zeros(25,x.shape[0],200,200)\n",
    "            i = 0\n",
    "            for k in range(im*25,(im*25)+25):\n",
    "                z[i] = trainset.__getitem__(k)[:,100:300,100:300]\n",
    "                i +=1\n",
    "            x = z\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            reconstruction = model(x)\n",
    "            loss_function = nn.MSELoss(size_average=True)\n",
    "            loss = loss_function(reconstruction, x)\n",
    "            #i = 0\n",
    "            #for image in x:\n",
    "                #images[image] = reconstruction[i]\n",
    "                #imshow_noax(image, normalize=False)\n",
    "                #imshow_noax(reconstruction[i], normalize=False)\n",
    "                #plt.imshow(image.detach().numpy().transpose(2,1,0))\n",
    "                #plt.imshow(reconstruction[i].detach().numpy().transpose(2,1,0))\n",
    "                #i += 1\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "            loss_history.append(loss.item())\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "        if e % print_every == 0:\n",
    "            print('Iteration %d, loss = %.4f' % (e, loss.item()))\n",
    "            #check_accuracy_part34(loader_val, model)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V. CIFAR-10 open-ended challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 0.0224\n",
      "\n",
      "Iteration 5, loss = 0.0040\n",
      "\n",
      "Iteration 10, loss = 0.0036\n",
      "\n",
      "Iteration 15, loss = 0.0035\n",
      "\n",
      "Iteration 20, loss = 0.0037\n",
      "\n",
      "Iteration 25, loss = 0.0031\n",
      "\n",
      "Iteration 30, loss = 0.0028\n",
      "\n",
      "Iteration 35, loss = 0.0026\n",
      "\n",
      "Iteration 40, loss = 0.0023\n",
      "\n",
      "Iteration 45, loss = 0.0020\n",
      "\n",
      "Iteration 50, loss = 0.0020\n",
      "\n",
      "Iteration 55, loss = 0.0019\n",
      "\n",
      "Iteration 60, loss = 0.0017\n",
      "\n",
      "Iteration 65, loss = 0.0018\n",
      "\n",
      "Iteration 70, loss = 0.0016\n",
      "\n",
      "Iteration 75, loss = 0.0018\n",
      "\n",
      "Iteration 80, loss = 0.0017\n",
      "\n",
      "Iteration 85, loss = 0.0016\n",
      "\n",
      "Iteration 90, loss = 0.0016\n",
      "\n",
      "Iteration 95, loss = 0.0015\n",
      "\n",
      "Iteration 100, loss = 0.0014\n",
      "\n",
      "Iteration 105, loss = 0.0015\n",
      "\n",
      "Iteration 110, loss = 0.0014\n",
      "\n",
      "Iteration 115, loss = 0.0018\n",
      "\n",
      "Iteration 120, loss = 0.0015\n",
      "\n",
      "Iteration 125, loss = 0.0011\n",
      "\n",
      "Iteration 130, loss = 0.0009\n",
      "\n",
      "Iteration 135, loss = 0.0010\n",
      "\n",
      "Iteration 140, loss = 0.0013\n",
      "\n",
      "Iteration 145, loss = 0.0010\n",
      "\n",
      "Iteration 150, loss = 0.0005\n",
      "\n",
      "Iteration 155, loss = 0.0005\n",
      "\n",
      "Iteration 160, loss = 0.0009\n",
      "\n",
      "Iteration 165, loss = 0.0006\n",
      "\n",
      "Iteration 170, loss = 0.0004\n",
      "\n",
      "Iteration 175, loss = 0.0028\n",
      "\n",
      "Iteration 180, loss = 0.0024\n",
      "\n",
      "Iteration 185, loss = 0.0019\n",
      "\n",
      "Iteration 190, loss = 0.0017\n",
      "\n",
      "Iteration 195, loss = 0.0014\n",
      "\n",
      "Iteration 200, loss = 0.0012\n",
      "\n",
      "Iteration 205, loss = 0.0014\n",
      "\n",
      "Iteration 210, loss = 0.0013\n",
      "\n",
      "Iteration 215, loss = 0.0013\n",
      "\n",
      "Iteration 220, loss = 0.0008\n",
      "\n",
      "Iteration 225, loss = 0.0009\n",
      "\n",
      "Iteration 230, loss = 0.0012\n",
      "\n",
      "Iteration 235, loss = 0.0012\n",
      "\n",
      "Iteration 240, loss = 0.0008\n",
      "\n",
      "Iteration 245, loss = 0.0007\n",
      "\n",
      "Iteration 250, loss = 0.0008\n",
      "\n",
      "Iteration 255, loss = 0.0008\n",
      "\n",
      "Iteration 260, loss = 0.0007\n",
      "\n",
      "Iteration 265, loss = 0.0004\n",
      "\n",
      "Iteration 270, loss = 0.0005\n",
      "\n",
      "Iteration 275, loss = 0.0007\n",
      "\n",
      "Iteration 280, loss = 0.0005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #         \n",
    "# Experiment with any architectures, optimizers, and hyperparameters.          #\n",
    "# Achieve AT LEAST 70% accuracy on the *validation set* within 10 epochs.      #\n",
    "#                                                                              #\n",
    "# Note that you can use the check_accuracy function to evaluate on either      #\n",
    "# the test set or the validation set, by passing either loader_test or         #\n",
    "# loader_val as the second argument to check_accuracy. You should not touch    #\n",
    "# the test set until you have finished your architecture and  hyperparameter   #\n",
    "# tuning, and only run the test set once at the end to report a final value.   #\n",
    "################################################################################\n",
    "class TestConvNet(nn.Module):\n",
    "    def __init__(self,channels,size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_1_compress = nn.Conv2d(channels, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.relu_1_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_2_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_2_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_2_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_3_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_3_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_3_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_4_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_4_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_4_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_5_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_5_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_5_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_6_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_6_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_6_compress = nn.ReLU()\n",
    "\n",
    "        self.conv_downsize_compress = nn.Conv2d(size, size, kernel_size=3,stride=2,padding=1,bias=True)\n",
    "        self.batchnorm_downsize_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_downsize_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_7_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_7_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_7_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_8_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_8_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_8_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_9_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_9_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_9_compress = nn.ReLU()\n",
    "        \n",
    "        self.conv_10_compress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_10_compress = nn.BatchNorm2d(size)\n",
    "        self.relu_10_compress = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_compress_final = nn.Conv2d(size, channels, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        \n",
    "        self.upscaling = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.conv_1_decompress = nn.Conv2d(channels, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.relu_1_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_2_decompress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_2_decompress = nn.BatchNorm2d(size)\n",
    "        self.relu_2_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_3_decompress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_3_decompress = nn.BatchNorm2d(size)\n",
    "        self.relu_3_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_4_decompress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_4_decompress = nn.BatchNorm2d(size)\n",
    "        self.relu_4_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_5_decompress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_5_decompress = nn.BatchNorm2d(size)\n",
    "        self.relu_5_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_6_decompress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_6_decompress = nn.BatchNorm2d(size)\n",
    "        self.relu_6_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_7_decompress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_7_decompress = nn.BatchNorm2d(size)\n",
    "        self.relu_7_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_8_decompress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_8_decompress = nn.BatchNorm2d(size)\n",
    "        self.relu_8_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_9_decompress = nn.Conv2d(size, size, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.batchnorm_9_decompress = nn.BatchNorm2d(size)\n",
    "        self.relu_9_decompress = nn.ReLU()\n",
    "        \n",
    "        self.conv_10_decompress = nn.Conv2d(size, 3, kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = None\n",
    "        model = torch.nn.Sequential( \n",
    "            \n",
    "            self.conv_1_compress,\n",
    "            self.relu_1_compress,\n",
    "        \n",
    "            self.conv_2_compress,\n",
    "            self.batchnorm_2_compress,\n",
    "            self.relu_2_compress,\n",
    "            \n",
    "            self.conv_3_compress,\n",
    "            self.batchnorm_3_compress,\n",
    "            self.relu_3_compress,\n",
    "            \n",
    "            self.conv_4_compress,\n",
    "            self.batchnorm_4_compress,\n",
    "            self.relu_4_compress,\n",
    "            \n",
    "            self.conv_5_compress,\n",
    "            self.batchnorm_5_compress,\n",
    "            self.relu_5_compress,\n",
    "            \n",
    "            self.conv_6_compress,\n",
    "            self.batchnorm_6_compress,\n",
    "            self.relu_6_compress,\n",
    "            \n",
    "            self.conv_downsize_compress,\n",
    "            self.batchnorm_downsize_compress,\n",
    "            self.relu_downsize_compress,\n",
    "            \n",
    "            self.conv_7_compress,\n",
    "            self.batchnorm_7_compress,\n",
    "            self.relu_7_compress,\n",
    "            \n",
    "            self.conv_8_compress,\n",
    "            self.batchnorm_8_compress,\n",
    "            self.relu_8_compress,\n",
    "            \n",
    "            self.conv_9_compress,\n",
    "            self.batchnorm_9_compress,\n",
    "            self.relu_9_compress,\n",
    "            \n",
    "            self.conv_10_compress,\n",
    "            self.batchnorm_10_compress,\n",
    "            self.relu_10_compress,\n",
    "            \n",
    "            self.conv_compress_final,\n",
    "        \n",
    "            self.upscaling,\n",
    "            \n",
    "            self.conv_1_decompress,\n",
    "            self.relu_1_decompress,\n",
    "        \n",
    "            self.conv_2_decompress,\n",
    "            self.batchnorm_2_decompress,\n",
    "            self.relu_2_decompress,\n",
    "            \n",
    "            self.conv_3_decompress,\n",
    "            self.batchnorm_3_decompress,\n",
    "            self.relu_3_decompress,\n",
    "            \n",
    "            self.conv_4_decompress,\n",
    "            self.batchnorm_4_decompress,\n",
    "            self.relu_4_decompress,\n",
    "            \n",
    "            self.conv_5_decompress,\n",
    "            self.batchnorm_5_decompress,\n",
    "            self.relu_5_decompress,\n",
    "            \n",
    "            self.conv_6_decompress,\n",
    "            self.batchnorm_6_decompress,\n",
    "            self.relu_6_decompress,\n",
    "            \n",
    "            self.conv_7_decompress,\n",
    "            self.batchnorm_7_decompress,\n",
    "            self.relu_7_decompress,\n",
    "            \n",
    "            self.conv_8_decompress,\n",
    "            self.batchnorm_8_decompress,\n",
    "            self.relu_8_decompress,\n",
    "            \n",
    "            self.conv_9_decompress,\n",
    "            self.batchnorm_9_decompress,\n",
    "            self.relu_9_decompress,\n",
    "        \n",
    "            self.conv_10_decompress\n",
    "\n",
    "            \n",
    "        ).to(device)\n",
    "        scores = model(x)\n",
    "        return scores\n",
    "    \n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        return x\n",
    "\n",
    "channels = 3\n",
    "size = 32\n",
    "\n",
    "model = TestConvNet(channels, size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-3)\n",
    "                     #momentum=0.9, nesterov=True)#optim.SGD(model.parameters(), lr=5e-3)\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             \n",
    "################################################################################\n",
    "\n",
    "# You should get at least 70% accuracy\n",
    "train_part34(model, optimizer, epochs=2500)\n",
    "\n",
    "\n",
    "# def train(epoch, log_interval=100):\n",
    "#     model.train()  # set training mode\n",
    "#     iteration = 0\n",
    "#     for ep in range(epoch):\n",
    "#         for data in trainset:\n",
    "#             data = data.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             output = model(data)\n",
    "#             loss = F.nll_loss(output, target)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             if iteration % log_interval == 0:\n",
    "#                 print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                     ep, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "#                     100. * batch_idx / len(trainset_loader), loss.item()))\n",
    "#             iteration += 1\n",
    "#         test()\n",
    "# def test():\n",
    "#     model.eval()  # set evaluation mode\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data in testset_loader:\n",
    "#             data = data.to(device), target.to(device)\n",
    "#             output = model(data)\n",
    "#             test_loss += F.nll_loss(output, target, size_average=False).item() # sum up batch loss\n",
    "#             pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "#     test_loss /= len(testset_loader.dataset)\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(testset_loader.dataset),\n",
    "#         100. * correct / len(testset_loader.dataset)))\n",
    "# train(5)\n",
    "# # create a brand new model\n",
    "# model = Net().to(device)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "# dataiter = iter(trainset_loader)\n",
    "# images = dataiter.next()\n",
    "\n",
    "z = torch.zeros(20,3,200,200)\n",
    "i = 0\n",
    "for k in range(0,20):\n",
    "    z[i] = trainset.__getitem__(k)[:,100:300,100:300]\n",
    "    i +=1\n",
    "originals = z\n",
    "originals = originals.to(device=device, dtype=dtype)\n",
    "reconstruction = model(originals)\n",
    "#for i in range(20):\n",
    "#    plt.figure()\n",
    "#    org = originals[i].cpu().detach().numpy().transpose(1,2,0)\n",
    "#    plt.subplot(1, 2, 1)\n",
    "#    imshow_noax(original.detach().numpy().transpose(1,2,0), normalize=False)\n",
    "#    plt.title('Original image')\n",
    "#    plt.subplot(1, 2, 2)\n",
    "#    rec = reconstruction.detach().numpy().transpose(1,2,0)\n",
    "#    imshow_noax(reconstruction.detach().numpy().transpose(1,2,0), normalize=False)\n",
    "#    plt.title('Reconstructed image')\n",
    "#    plt.show()\n",
    "    #imshow(torchvision.utils.make_grid(originals[i].cpu()))\n",
    "    #imshow(torchvision.utils.make_grid(reconstruction[i].detach().cpu()))\n",
    "#    break\n",
    "    \n",
    "\n",
    "#reconstruction = model(pic)\n",
    "# show images\n",
    "#imshow(torchvision.utils.make_grid(pic))\n",
    "# print labels\n",
    "#print(' '.join('%5s' % labels[j] for j in range(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(20):\n",
    "    plt.figure()\n",
    "    org = originals[i].cpu().detach().numpy().transpose(1,2,0)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    imshow_noax(org, normalize=False)\n",
    "    plt.title('Original image')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    rec = reconstruction[i].cpu().detach().numpy().transpose(1,2,0)\n",
    "    imshow_noax(rec, normalize=False)\n",
    "    plt.title('Reconstructed image')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
