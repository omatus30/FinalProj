{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import chest_xray_code.data.xrays as preprocess_dataset\n",
    "import chest_xray_code.data.raw_reports as utils\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from models.NewConvModel import NewConvNet \n",
    "from loaders.MuseumLoader import MuseumLoader\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6029312 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/shared/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1311848 bytes but only got 785. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/shared/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "filenames = glob.glob(osp.join('museum_data/dataset_updated/training_set', '*.jpg'))\n",
    "#print(filenames)\n",
    "\n",
    "for filename in filenames:\n",
    "    image_fn = filename\n",
    "    try:\n",
    "        #print(image_fn)\n",
    "        image = Image.open(image_fn)\n",
    "        image = image.resize((200,200),Image.ANTIALIAS)\n",
    "    except IOError:\n",
    "        os.remove(image_fn)\n",
    "        print(image_fn)    \n",
    "\n",
    "    removed_name = False\n",
    "    if image is None:\n",
    "        os.remove(image_fn)\n",
    "        print(image_fn)\n",
    "        removed_name = True\n",
    "    image = np.array(image)\n",
    "\n",
    "    if image.shape != (200,200,3) and not removed_name:\n",
    "        os.remove(image_fn)\n",
    "        print(image_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "trainset = MuseumLoader(\n",
    "    root='museum_data/dataset_updated/training_set',\n",
    "    preload=False, transform=transforms.ToTensor(),\n",
    ")\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "trainset_loader = DataLoader(trainset, batch_size=20, shuffle=True, num_workers=32)\n",
    "\n",
    "# load the testset\n",
    "# testset = Data_SET(\n",
    "#     root='chest_xray_code/data/xrays',\n",
    "#     preload=True, transform=transforms.ToTensor(),\n",
    "# )\n",
    "#testset = trainset\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "#testset_loader = DataLoader(testset, batch_size=1000, shuffle=False, num_workers=1)\n",
    "\n",
    "print(len(trainset))\n",
    "#print(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "                T.ToTensor()\n",
    "                #T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "\n",
    "images = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    #dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 3\n",
    "size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "images = []\n",
    "for data in trainset_loader:\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        img = data.cpu().detach()\n",
    "    \n",
    "        for i in range(img.shape[0]):\n",
    "            individual_img = img[i]\n",
    "            individual_img = individual_img.numpy()\n",
    "            individual_img = np.transpose(individual_img, (1, 2, 0))\n",
    "            images.append(torch.from_numpy(individual_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss(size_average=True)\n",
    "total_comparisons = 0\n",
    "comparison_sum = 0\n",
    "for i in range(len(images)):\n",
    "    for j in range(len(images)):\n",
    "        if i != j:\n",
    "            comparison_sum += loss_function(images[i],images[j])\n",
    "            total_comparisons += 1\n",
    "homogeneity = comparison_sum / total_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11031649261713028\n"
     ]
    }
   ],
   "source": [
    "print(homogeneity.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
