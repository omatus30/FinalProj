{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import chest_xray_code.data.xrays as preprocess_dataset\n",
    "import chest_xray_code.data.raw_reports as utils\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from models.NewConvModel import NewConvNet \n",
    "from models.TestConvNet import TestConvNet\n",
    "from loaders.XrayLoader import XrayLoader\n",
    "from loaders.BloodCellLoader import BloodCellLoader\n",
    "from loaders.MuseumLoader import MuseumLoader\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "366\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "xray_set = XrayLoader(\n",
    "    root='chest_xray_code/data/xrays',\n",
    "    preload=False, transform=transforms.ToTensor(),\n",
    ")\n",
    "xray_loader = DataLoader(xray_set, batch_size=20, shuffle=True, num_workers=32)\n",
    "\n",
    "blood_set = BloodCellLoader(\n",
    "    root='blood_cells_data/dataset-master/JPEGImages',\n",
    "    preload=False, transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "blood_cell_loader = DataLoader(blood_set, batch_size=20, shuffle=True, num_workers=32)\n",
    "\n",
    "\n",
    "museum_set = MuseumLoader(\n",
    "    root='museum_data/dataset_updated/training_set',\n",
    "    preload=False, transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "museum_loader = DataLoader(museum_set, batch_size=20, shuffle=True, num_workers=32)\n",
    "\n",
    "print(len(museum_set))\n",
    "print(len(blood_set))\n",
    "print(len(xray_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "                T.ToTensor()\n",
    "                #T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "images = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    #dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 3\n",
    "size = 32\n",
    "#net_type = 'new' #'old'\n",
    "#original_dataset = 'blood_cell' #'museum' #'xray' \n",
    "#model = None\n",
    "#hook = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded blood5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'models.TestConvNet.TestConvNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "if model == None: #ensure that we don't keep loading it over and over\n",
    "    if net_type = 'new':\n",
    "        model = NewConvNet(channels,size,device)\n",
    "        if original_dataset == 'blood_cell':\n",
    "            model = torch.load('trained_models/blood5.pt')\n",
    "            print(\"loaded blood5.pt\")\n",
    "        elif original_dataset == 'museum':\n",
    "            model = torch.load('trained_models/new_museum.pt')\n",
    "            print(\"loaded new_museum.pt\")\n",
    "        else:\n",
    "            model = torch.load('trained_models/new_xray.pt')\n",
    "            print(\"loaded new_xray.pt\")\n",
    "    else:\n",
    "        model = TestConvNet(channels,size)\n",
    "        if original_dataset == 'blood_cell':\n",
    "            model = torch.load('trained_models/blood_200_1000.pt')\n",
    "            print(\"loaded blood_200_1000.pt\")\n",
    "        elif original_dataset == 'museum':\n",
    "            model = torch.load('trained_models/old_museum.pt')\n",
    "            print(\"loaded old_museum.pt\")\n",
    "        else:\n",
    "            model = torch.load('trained_models/xraymodelV2.pt')\n",
    "            print(\"loaded xraymodelV2.pt\")\n",
    "\n",
    "        model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the Compressed images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(img):\n",
    "    img = img.numpy()\n",
    "    if True:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = .9* (img - img_min) / (img_max - img_min) \n",
    "    return np.transpose(img, (1, 2, 0)) \n",
    "\n",
    "def save_compressed(self,input,output):\n",
    "    #for i in range(1):\n",
    "    img = output.cpu().detach()\n",
    "    for i in range(img.shape[0]):\n",
    "        individual_img = img[i]\n",
    "        images[1].append(prep(individual_img))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_original(data):\n",
    "    img = data.cpu().detach()\n",
    "\n",
    "    for i in range(img.shape[0]):\n",
    "        individual_img = img[i]\n",
    "        individual_img = individual_img.numpy()\n",
    "        individual_img = np.transpose(individual_img, (1, 2, 0))\n",
    "        images[0].append(individual_img)\n",
    "\n",
    "def visualize(net_type,original_dataset,cross_dataset,device):\n",
    "    model = None\n",
    "    \n",
    "\n",
    "    if model == None: #ensure that we don't keep loading it over and over\n",
    "        if net_type == 'new':\n",
    "            model = NewConvNet(channels,size,device)\n",
    "            if original_dataset == 'blood_cell':\n",
    "                model = torch.load('trained_models/blood5.pt')\n",
    "                print(\"loaded blood5.pt\")\n",
    "            elif original_dataset == 'museum':\n",
    "                model = torch.load('trained_models/new_museum.pt')\n",
    "                print(\"loaded new_museum.pt\")\n",
    "            else:\n",
    "                model = torch.load('trained_models/new_xray.pt')\n",
    "                print(\"loaded new_xray.pt\")\n",
    "        else:\n",
    "            model = TestConvNet(channels,size)\n",
    "            if original_dataset == 'blood_cell':\n",
    "                model = torch.load('trained_models/blood_200_1000.pt')\n",
    "                print(\"loaded blood_200_1000.pt\")\n",
    "            elif original_dataset == 'museum':\n",
    "                model = torch.load('trained_models/old_museum.pt')\n",
    "                print(\"loaded old_museum.pt\")\n",
    "            else:\n",
    "                model = torch.load('trained_models/xraymodelV2.pt')\n",
    "                print(\"loaded xraymodelV2.pt\")\n",
    "\n",
    "            model.to(device)\n",
    "            \n",
    "    if hook == None: \n",
    "        hook = model.conv_compress_final.register_forward_hook(save_compressed)     \n",
    "        \n",
    "        \n",
    "    if cross_dataset == 'museum':\n",
    "        cross_dataset_loader = museum_loader\n",
    "    elif cross_dataset == 'xray':\n",
    "        cross_dataset_loader = xray_loader\n",
    "    else:\n",
    "        cross_dataset_loader = blood_cell_loader\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.close(\"all\")\n",
    "\n",
    "\n",
    "    images = [[],[]]\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    reconstruction = None\n",
    "    for data in cross_dataset_loader:\n",
    "        with torch.no_grad():\n",
    "            if i > 0: break\n",
    "            data = data.to(device)\n",
    "            save_original(data)\n",
    "            reconstruction = model(data)\n",
    "            i+=1\n",
    "\n",
    "    for i in range(10):\n",
    "        plt.figure(figsize=(100,100))\n",
    "        #plt.figure()\n",
    "        org = images[0][i]\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.axis('off')\n",
    "        #imshow_noax(org, normalize=False)\n",
    "        plt.imshow(org)\n",
    "        plt.title('Original')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        rec = images[1][i]\n",
    "        plt.imshow(rec)\n",
    "        #imshow_noax(rec, normalize=False)\n",
    "        plt.title('Compressed')\n",
    "        plt.axis('off')\n",
    "        image_str = net_type + \"_\" + original_dataset + \"_\" +cross_dataset+\"_\"+str(i) + \".png\"\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.axis('off')\n",
    "        recon = reconstruction[i].cpu().detach()\n",
    "        recon = recon.numpy()\n",
    "        recon = np.transpose(recon,(1,2,0))\n",
    "        recon = np.clip(recon,0,1)\n",
    "        plt.imshow(recon)\n",
    "        plt.title('Reconstructed')\n",
    "        plt.savefig(\"cross_visualizations/\"+image_str)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-55664c6d3544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moriginal_dataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moriginal_datasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcross_dataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcross_datasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moriginal_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcross_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-2b00d5c148ac>\u001b[0m in \u001b[0;36mvisualize\u001b[0;34m(net_type, original_dataset, cross_dataset, device)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded new_museum.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trained_models/new_xray.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded new_xray.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "cross_datasets = ['xray','museum','blood_cell']#'museum' #'xray' #'blood_cell'\n",
    "net_types = ['new','old'] #'old'\n",
    "original_datasets = ['xray','museum','blood_cell'] #'museum' #'xray' \n",
    "\n",
    "for net_type in net_types:\n",
    "    for original_dataset in original_datasets:\n",
    "        for cross_dataset in cross_datasets:\n",
    "            visualize(net_type,original_dataset,cross_dataset,device)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the Reconstructed Images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
