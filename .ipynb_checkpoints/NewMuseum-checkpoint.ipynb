{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import chest_xray_code.data.xrays as preprocess_dataset\n",
    "import chest_xray_code.data.raw_reports as utils\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from models.NewConvModel import NewConvNet \n",
    "from loaders.MuseumLoader import MuseumLoader\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(osp.join('museum_data/dataset_updated/validation_set', '*.jpg'))\n",
    "#print(filenames)\n",
    "\n",
    "for filename in filenames:\n",
    "    image_fn = filename\n",
    "    try:\n",
    "        #print(image_fn)\n",
    "        image = Image.open(image_fn)\n",
    "        image = image.resize((200,200),Image.ANTIALIAS)\n",
    "    except IOError:\n",
    "        os.remove(image_fn)\n",
    "        print(image_fn)    \n",
    "\n",
    "    removed_name = False\n",
    "    if image is None:\n",
    "        os.remove(image_fn)\n",
    "        print(image_fn)\n",
    "        removed_name = True\n",
    "    image = np.array(image)\n",
    "\n",
    "    if image.shape != (200,200,3) and not removed_name:\n",
    "        os.remove(image_fn)\n",
    "        print(image_fn)\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "trainset = MuseumLoader(\n",
    "    root='museum_data/dataset_updated/validation_set',\n",
    "    preload=False, transform=transforms.ToTensor(),\n",
    ")\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "trainset_loader = DataLoader(trainset, batch_size=20, shuffle=True, num_workers=32)\n",
    "\n",
    "# load the testset\n",
    "# testset = Data_SET(\n",
    "#     root='chest_xray_code/data/xrays',\n",
    "#     preload=True, transform=transforms.ToTensor(),\n",
    "# )\n",
    "#testset = trainset\n",
    "# Use the torch dataloader to iterate through the dataset\n",
    "#testset_loader = DataLoader(testset, batch_size=1000, shuffle=False, num_workers=1)\n",
    "\n",
    "print(len(trainset))\n",
    "#print(len(testset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "museum_data/dataset_updated/validation_set/190.jpg\n",
      "museum_data/dataset_updated/validation_set/0875.jpg\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/cfurrer/FinalProj/loaders/MuseumLoader.py\", line 106, in __getitem__\n    image = self.transform(image)\nUnboundLocalError: local variable 'image' referenced before assignment\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cb0935e83bce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# show images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: Traceback (most recent call last):\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/cfurrer/FinalProj/loaders/MuseumLoader.py\", line 106, in __getitem__\n    image = self.transform(image)\nUnboundLocalError: local variable 'image' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "def imshow_noax(img, normalize=True):\n",
    "    #Tiny helper to show images as uint8 and remove axis labels \n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "    plt.imshow(img)\n",
    "    plt.gca().axis('off')\n",
    "    \n",
    "    # functions to show an image\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainset_loader)\n",
    "\n",
    "images = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 100\n",
    "\n",
    "transform = T.Compose([\n",
    "                T.ToTensor()\n",
    "                #T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "loader_train = trainset\n",
    "images = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    #dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval=100):\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.train()  # set training mode\n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        for batch_idx, (data) in enumerate(trainset_loader):\n",
    "            data = data.to(device=device, dtype=dtype)\n",
    "            optimizer.zero_grad()\n",
    "            #print(data.shape)\n",
    "            reconstruction = model(data)\n",
    "            loss_function = nn.MSELoss(size_average=True)\n",
    "            loss = loss_function(reconstruction, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if ep % print_every == 0:\n",
    "            print('Iteration %d, loss = %.4f' % (ep, loss.item()))\n",
    "            print()\n",
    "\n",
    "def test():\n",
    "    model.eval()  # set evaluation mode\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testset_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(testset_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(testset_loader.dataset),\n",
    "        100. * correct / len(testset_loader.dataset)))\n",
    "\n",
    "def save_compressed(self,input,output):\n",
    "    #for i in range(1):\n",
    "    img = output.cpu().detach()\n",
    "    for i in range(img.shape[0]):\n",
    "\n",
    "        individual_img = img[i]\n",
    "        axarr[i,1].axis('off')\n",
    "        axarr[i,1].imshow(prep(individual_img))\n",
    "        images[1].append(prep(individual_img))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 3\n",
    "size = 32\n",
    "model = NewConvNet(channels,size,device)\n",
    "#hook = model.conv_compress_final.register_forward_hook(save_compressed)\n",
    "#hook.remove()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-3) \n",
    "train(model,1700)\n",
    "torch.save(model, 'new_museum.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class save_output(nn.Module):\n",
    "    def forward(self, x):\n",
    "       \n",
    "        with torch.no_grad():\n",
    "            img = x.cpu().detach()\n",
    "            imshow_noax(torchvision.utils.make_grid(img))\n",
    "        return x\n",
    "\"\"\"\n",
    "plt.close(\"all\")\n",
    "f,axarr = plt.subplots(20, 2,figsize=(400,400))\n",
    "\n",
    "f.tight_layout()\n",
    "f.subplots_adjust(left=0, bottom=0, right=.1, top=.1, wspace=0, hspace=.1)\n",
    "\n",
    "images = [[],[]]\n",
    "\n",
    "def prep(img):\n",
    "    img = img.numpy()\n",
    "    if True:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "    return np.transpose(img, (1, 2, 0))\n",
    "    \n",
    "def save_compressed(self,input,output):\n",
    "    #for i in range(1):\n",
    "    img = output.cpu().detach()\n",
    "    for i in range(img.shape[0]):\n",
    "\n",
    "        individual_img = img[i]\n",
    "        axarr[i,1].axis('off')\n",
    "        axarr[i,1].imshow(prep(individual_img))\n",
    "        images[1].append(prep(individual_img))\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "def save_original(data):\n",
    "    img = data.cpu().detach()\n",
    "    \n",
    "    for i in range(img.shape[0]):\n",
    "        individual_img = img[i]\n",
    "        individual_img = individual_img.numpy()\n",
    "        individual_img = np.transpose(individual_img, (1, 2, 0))\n",
    "        axarr[i,0].axis('off')\n",
    "        axarr[i,0].imshow(individual_img)\n",
    "        images[0].append(individual_img)\n",
    "\n",
    "\n",
    "\n",
    "model = torch.load('MuseumModel.pt')\n",
    "\n",
    "model.conv_compress_final.register_forward_hook(save_compressed)\n",
    "i = 0\n",
    "reconstruction = None\n",
    "for data in trainset_loader:\n",
    "    with torch.no_grad():\n",
    "        if i > 0: break\n",
    "        data = data.to(device)\n",
    "        display_original(data)\n",
    "        reconstruction = model(data)\n",
    "        i+=1\n",
    "\"\"\"\n",
    "for i in range(20):\n",
    "    plt.figure()\n",
    "    org = images[0][i]\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.axis('off')\n",
    "    #imshow_noax(org, normalize=False)\n",
    "    plt.imshow(org)\n",
    "    plt.title('Original image')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    rec = images[1][i]\n",
    "    plt.imshow(rec)\n",
    "    #imshow_noax(rec, normalize=False)\n",
    "    plt.title('Compressed Image')\n",
    "    plt.axis('off')\n",
    "    image_str = str(i) + \".png\"\n",
    "    plt.savefig(image_str)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(20):\n",
    "#    plt.figure()\n",
    "#    org = originals[i].cpu().detach().numpy().transpose(1,2,0)\n",
    "    #org = np.maximum(org,1)\n",
    "    #org = np.minimum(org,0)\n",
    "#    plt.subplot(1, 2, 1)\n",
    "#    imshow_noax(org, normalize=False)\n",
    "#    plt.title('Original image')\n",
    "#    plt.subplot(1, 2, 2)\n",
    "#    rec = reconstruction[i].cpu().detach().numpy().transpose(1,2,0)\n",
    "    #rec = np.maximum(rec,1)\n",
    "    #rec = np.minimum(rec,0)\n",
    "#    imshow_noax(rec, normalize=False)\n",
    "#    plt.title('Reconstructed image')\n",
    "#    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
